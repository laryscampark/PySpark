{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP+t/FHswwRy5fHAppti/zP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/laryscampark/PySpark/blob/main/Introdu%C3%A7ao_pypsark.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Introduçao ao PySpark"
      ],
      "metadata": {
        "id": "boZWCs3wPbta"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Instalação do pyspark"
      ],
      "metadata": {
        "id": "av7DZpT-P0WM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "af1T0M-2NnKZ"
      },
      "outputs": [],
      "source": [
        "!pip install pyspark"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importação das bibliotecas / funções"
      ],
      "metadata": {
        "id": "ituENLlzP4OS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import *\n",
        "from pyspark.sql.types import *"
      ],
      "metadata": {
        "id": "4GxK6HFjPU0W"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Criar/Iniciar Sessão Pyspark"
      ],
      "metadata": {
        "id": "6i4hniw-QJ7Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "spark = (\n",
        "    SparkSession.builder\n",
        "    .master('local')\n",
        "    .appName('Pyspark_intro')\n",
        "    .getOrCreate()\n",
        ")"
      ],
      "metadata": {
        "id": "9hzpF9KqQO7-"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Criar DF - ler arquivo\n",
        "InferSchema - Aqui um dos métodos que é implementado é o inferSchema, responsável por dizer ao Spark qual é o schema esperado para que este data source funcione. No caso, esperamos que o dataframe possua uma coluna chamada value, coluna esta que será usada como corpo da mensagem gerada no SQS"
      ],
      "metadata": {
        "id": "DT8wrfDuRAsV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = spark.read.csv('./teste.csv', sep=';', header=True, inferSchema=False)"
      ],
      "metadata": {
        "id": "3YXcqWthRFCi"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Exibir o dataframe"
      ],
      "metadata": {
        "id": "Jcm29-DgUopm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.show(10)"
      ],
      "metadata": {
        "id": "LjNsLMV_UbXt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Verificar tipos de colunas"
      ],
      "metadata": {
        "id": "5W7ik0bvWNkR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.printSchema()"
      ],
      "metadata": {
        "id": "-LAKMpFgWTC6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "verificar dados nulos - (transformando em pandas e verificando se é nulo e somando)"
      ],
      "metadata": {
        "id": "m9rJUQOjWdhg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.toPandas().isna().sum()"
      ],
      "metadata": {
        "id": "OXg06snkWfza"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Verificar dados nulos usando pyspark"
      ],
      "metadata": {
        "id": "S76b3vbKXSXo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for coluna in df.columns:\n",
        "  print(coluna, df.filter(df[coluna].isNull()).count())"
      ],
      "metadata": {
        "id": "nJysnB3-XW11"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Renomear colunas com pyspark = df = df.withColumnRenamed('nome da coluna que quero mudar', 'nome atual')"
      ],
      "metadata": {
        "id": "hhhJlkYLYA1X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "nome das colunas"
      ],
      "metadata": {
        "id": "jSCn6Ia1aKNR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns"
      ],
      "metadata": {
        "id": "J-u8Az4WaHaZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "selecionar as colunas"
      ],
      "metadata": {
        "id": "RKJhzRXzaPsC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.select('nome', 'estado').show(5)"
      ],
      "metadata": {
        "id": "Xx9jkP9uaRBx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "outra forma de chamar coluna"
      ],
      "metadata": {
        "id": "TOqFu94aaxBV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.select(col('nome'),col('estado')).show(5)"
      ],
      "metadata": {
        "id": "kRY7xBcDay_D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Selecionar colunas com alias (df.select(col('email'.alias('email')).show(5)"
      ],
      "metadata": {
        "id": "0Sf-Qel4be6n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Filtrar os dataframe"
      ],
      "metadata": {
        "id": "4IGW3fCCcXNW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.filter(col('Nome')==\"Daniel Sanchez\").show(10)\n"
      ],
      "metadata": {
        "id": "hdXSJBdmctYk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Organizar os select"
      ],
      "metadata": {
        "id": "eJEOhTnL2abe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.select('Nome Estado Cidade'.split()).show(5)"
      ],
      "metadata": {
        "id": "P_m6RM8n2cK9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.select('nome', 'cidade', 'estado').show(5)"
      ],
      "metadata": {
        "id": "_o8uRL1s4LRA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}